{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_sprint13_IntroTF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNN6Od6QgjhSAbcUvHnZ33A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanhnguyen2612/diveintocode-ml/blob/master/ML_sprint13_IntroTF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNlDrYNML1pl"
      },
      "source": [
        "# Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWFNCj99ZfRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca9d576-6a41-4f44-9e86-e63999c7d3b3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq3diL1Jl_8j"
      },
      "source": [
        "## [Problem 1] Looking back on the scratch\n",
        "\n",
        "*   Have to initialize the weights & bias\n",
        "*   Need epoch loop\n",
        "*   Determine the number of nodes at each layer\n",
        "*   Determine activation function and optimizer for each layer\n",
        "*   Determine mini-batch size\n",
        "*   Compute loss function\n",
        "*   Predict with validation data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "LPnsKeXmn7pf",
        "outputId": "13b27082-0223-4007-f0f7-f7fd0ac1cd8b"
      },
      "source": [
        "df = pd.read_csv('Iris.csv')\n",
        "data = df[df['Species'].isin(['Iris-versicolor', 'Iris-virginica'])]\n",
        "data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>51</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.4</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>52</td>\n",
              "      <td>6.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>53</td>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>54</td>\n",
              "      <td>5.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>55</td>\n",
              "      <td>6.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.6</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>146</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>147</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id  SepalLengthCm  ...  PetalWidthCm          Species\n",
              "50    51            7.0  ...           1.4  Iris-versicolor\n",
              "51    52            6.4  ...           1.5  Iris-versicolor\n",
              "52    53            6.9  ...           1.5  Iris-versicolor\n",
              "53    54            5.5  ...           1.3  Iris-versicolor\n",
              "54    55            6.5  ...           1.5  Iris-versicolor\n",
              "..   ...            ...  ...           ...              ...\n",
              "145  146            6.7  ...           2.3   Iris-virginica\n",
              "146  147            6.3  ...           1.9   Iris-virginica\n",
              "147  148            6.5  ...           2.0   Iris-virginica\n",
              "148  149            6.2  ...           2.3   Iris-virginica\n",
              "149  150            5.9  ...           1.8   Iris-virginica\n",
              "\n",
              "[100 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVjThK8co_p1"
      },
      "source": [
        "X = data.loc[:, ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
        "y = data['Species']\n",
        "y = np.where(y == 'Iris-versicolor', 0, 1)\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "y = y.astype(np.int32)[:, np.newaxis]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2UV8_n6sUCz",
        "outputId": "63735d6b-d7e9-47ef-b860-e3ab9d8b59c7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.8, random_state=0)\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((64, 4), (16, 4), (20, 4), (64, 1), (16, 1), (20, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWgnyjiXpQsD"
      },
      "source": [
        "## [Problem 2] Consider the correspondence between scratch and TensorFlow\n",
        "\n",
        "*   Tensorflow initializes weight and bias variables with global_variables_initializer() (only need to specify shapes)\n",
        "*   Built-in activation function (ReLU, Sigmoid, etc.)\n",
        "*   No hard code operation formulas (matmul, add, etc.)\n",
        "*   Built-in optimizer, loss function, etc.\n",
        "\n",
        "=> No need to write code from scratch which can be really annoyed and hard to debug."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRQXYF6TNv70"
      },
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    Iterator to get a mini-batch\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : The following forms of ndarray, shape (n_samples, n_features)\n",
        "      Training data\n",
        "    y : The following form of ndarray, shape (n_samples, 1)\n",
        "      Correct answer value\n",
        "    batch_size : int\n",
        "      Batch size\n",
        "    seed : int\n",
        "      NumPy random number seed\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size=10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_idx = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_idx]\n",
        "        self.y = y[shuffle_idx]\n",
        "        self._stop = np.ceil(X.shape[0] / self.batch_size).astype(np.int)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        p0 = item * self.batch_size\n",
        "        p1 = (item + 1) * self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "    \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter * self.batch_size\n",
        "        p1 = (self._counter + 1) * self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CelSRRcsuFFK"
      },
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 10\n",
        "num_epochs = 100\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "\n",
        "#Determine the shape of the argument to be passed to the calculation graph\n",
        "X_placeholder = tf.placeholder(tf.float32, [None, n_input])\n",
        "Y_placeholder = tf.placeholder(tf.float32, [None, n_classes])\n",
        "\n",
        "# train mini batch iterator\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "def example_net(x):\n",
        "    \"\"\"\n",
        "    Simple 3-layer neural network\n",
        "    \"\"\"\n",
        "    tf.random.set_random_seed(0)\n",
        "\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3']\n",
        "    return layer_output\n",
        "\n",
        "logits = example_net(X_placeholder)\n",
        "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y_placeholder, logits=logits))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Estimate\n",
        "correct_pred = tf.equal(tf.sign(Y_placeholder - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
        "\n",
        "# Accuracy\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Init variable weight and bias\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6SaWEBiyx0x",
        "outputId": "83c74aaf-dbb7-49e3-8908-9a69163709b6"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        total_batch = np.ceil(X_train.shape[0] / batch_size).astype(np.int64)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "\n",
        "        for i, (mini_X, mini_y) in enumerate(get_mini_batch_train):\n",
        "            sess.run(train_op, feed_dict={X_placeholder: mini_X, Y_placeholder: mini_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X_placeholder: mini_X, Y_placeholder: mini_y})\n",
        "            total_loss += loss\n",
        "        \n",
        "        total_loss /= n_samples\n",
        "        val_loss, acc = sess.run([loss_op, accuracy], feed_dict={X_placeholder: X_val, Y_placeholder: y_val})\n",
        "\n",
        "        print(f\"Epoch {epoch}, loss: {total_loss:.4f}, val_loss: {val_loss:.4f}, acc: {acc:.3f}\")\n",
        "    \n",
        "    test_acc = sess.run(accuracy, feed_dict={X_placeholder: X_test, Y_placeholder: y_test})\n",
        "    print(f\"Test acc: {test_acc:.3f}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss: 7.0241, val_loss: 67.6860, acc: 0.375\n",
            "Epoch 1, loss: 3.4241, val_loss: 23.4026, acc: 0.312\n",
            "Epoch 2, loss: 1.9387, val_loss: 11.6681, acc: 0.375\n",
            "Epoch 3, loss: 2.0917, val_loss: 13.1400, acc: 0.312\n",
            "Epoch 4, loss: 1.7685, val_loss: 17.7284, acc: 0.312\n",
            "Epoch 5, loss: 1.6097, val_loss: 12.9607, acc: 0.312\n",
            "Epoch 6, loss: 1.4402, val_loss: 10.0593, acc: 0.312\n",
            "Epoch 7, loss: 1.3704, val_loss: 9.4797, acc: 0.312\n",
            "Epoch 8, loss: 1.2536, val_loss: 9.8518, acc: 0.312\n",
            "Epoch 9, loss: 1.1476, val_loss: 8.5670, acc: 0.375\n",
            "Epoch 10, loss: 1.0930, val_loss: 8.0430, acc: 0.375\n",
            "Epoch 11, loss: 1.0412, val_loss: 7.8791, acc: 0.375\n",
            "Epoch 12, loss: 0.9804, val_loss: 7.1233, acc: 0.375\n",
            "Epoch 13, loss: 0.9326, val_loss: 6.7908, acc: 0.375\n",
            "Epoch 14, loss: 0.8792, val_loss: 6.2492, acc: 0.375\n",
            "Epoch 15, loss: 0.8304, val_loss: 5.7681, acc: 0.375\n",
            "Epoch 16, loss: 0.7835, val_loss: 5.2886, acc: 0.438\n",
            "Epoch 17, loss: 0.7384, val_loss: 4.8037, acc: 0.438\n",
            "Epoch 18, loss: 0.6961, val_loss: 4.3575, acc: 0.500\n",
            "Epoch 19, loss: 0.6543, val_loss: 3.9175, acc: 0.500\n",
            "Epoch 20, loss: 0.6136, val_loss: 3.5188, acc: 0.500\n",
            "Epoch 21, loss: 0.5738, val_loss: 3.1371, acc: 0.500\n",
            "Epoch 22, loss: 0.5349, val_loss: 2.7697, acc: 0.500\n",
            "Epoch 23, loss: 0.4973, val_loss: 2.4528, acc: 0.562\n",
            "Epoch 24, loss: 0.4606, val_loss: 2.1728, acc: 0.562\n",
            "Epoch 25, loss: 0.4255, val_loss: 1.9324, acc: 0.625\n",
            "Epoch 26, loss: 0.3919, val_loss: 1.7049, acc: 0.625\n",
            "Epoch 27, loss: 0.3609, val_loss: 1.5248, acc: 0.688\n",
            "Epoch 28, loss: 0.3326, val_loss: 1.3725, acc: 0.750\n",
            "Epoch 29, loss: 0.3071, val_loss: 1.2386, acc: 0.750\n",
            "Epoch 30, loss: 0.2851, val_loss: 1.1453, acc: 0.750\n",
            "Epoch 31, loss: 0.2647, val_loss: 1.0364, acc: 0.750\n",
            "Epoch 32, loss: 0.2466, val_loss: 0.9368, acc: 0.750\n",
            "Epoch 33, loss: 0.2297, val_loss: 0.8304, acc: 0.750\n",
            "Epoch 34, loss: 0.2155, val_loss: 0.7243, acc: 0.750\n",
            "Epoch 35, loss: 0.2024, val_loss: 0.6215, acc: 0.750\n",
            "Epoch 36, loss: 0.1920, val_loss: 0.5405, acc: 0.812\n",
            "Epoch 37, loss: 0.1815, val_loss: 0.4516, acc: 0.812\n",
            "Epoch 38, loss: 0.1735, val_loss: 0.4015, acc: 0.812\n",
            "Epoch 39, loss: 0.1643, val_loss: 0.3323, acc: 0.812\n",
            "Epoch 40, loss: 0.1574, val_loss: 0.2935, acc: 0.875\n",
            "Epoch 41, loss: 0.1496, val_loss: 0.2519, acc: 0.875\n",
            "Epoch 42, loss: 0.1429, val_loss: 0.2206, acc: 0.875\n",
            "Epoch 43, loss: 0.1364, val_loss: 0.1932, acc: 0.875\n",
            "Epoch 44, loss: 0.1302, val_loss: 0.1684, acc: 0.875\n",
            "Epoch 45, loss: 0.1244, val_loss: 0.1464, acc: 0.875\n",
            "Epoch 46, loss: 0.1188, val_loss: 0.1264, acc: 0.875\n",
            "Epoch 47, loss: 0.1139, val_loss: 0.1098, acc: 0.875\n",
            "Epoch 48, loss: 0.1091, val_loss: 0.0947, acc: 0.938\n",
            "Epoch 49, loss: 0.1050, val_loss: 0.0833, acc: 0.938\n",
            "Epoch 50, loss: 0.1007, val_loss: 0.0712, acc: 1.000\n",
            "Epoch 51, loss: 0.0975, val_loss: 0.0653, acc: 1.000\n",
            "Epoch 52, loss: 0.0932, val_loss: 0.0531, acc: 1.000\n",
            "Epoch 53, loss: 0.0915, val_loss: 0.0557, acc: 1.000\n",
            "Epoch 54, loss: 0.0862, val_loss: 0.0390, acc: 1.000\n",
            "Epoch 55, loss: 0.0875, val_loss: 0.0598, acc: 0.938\n",
            "Epoch 56, loss: 0.0790, val_loss: 0.0376, acc: 1.000\n",
            "Epoch 57, loss: 0.0871, val_loss: 0.0935, acc: 0.938\n",
            "Epoch 58, loss: 0.0723, val_loss: 0.0862, acc: 0.938\n",
            "Epoch 59, loss: 0.0936, val_loss: 0.1731, acc: 0.938\n",
            "Epoch 60, loss: 0.0693, val_loss: 0.1648, acc: 0.938\n",
            "Epoch 61, loss: 0.1047, val_loss: 0.2714, acc: 0.938\n",
            "Epoch 62, loss: 0.0711, val_loss: 0.1687, acc: 0.938\n",
            "Epoch 63, loss: 0.1072, val_loss: 0.3122, acc: 0.938\n",
            "Epoch 64, loss: 0.0738, val_loss: 0.1538, acc: 0.938\n",
            "Epoch 65, loss: 0.1069, val_loss: 0.3194, acc: 0.938\n",
            "Epoch 66, loss: 0.0757, val_loss: 0.1524, acc: 0.938\n",
            "Epoch 67, loss: 0.1082, val_loss: 0.3200, acc: 0.938\n",
            "Epoch 68, loss: 0.0780, val_loss: 0.1584, acc: 0.938\n",
            "Epoch 69, loss: 0.1114, val_loss: 0.3153, acc: 0.938\n",
            "Epoch 70, loss: 0.0808, val_loss: 0.1600, acc: 0.938\n",
            "Epoch 71, loss: 0.1139, val_loss: 0.2888, acc: 0.938\n",
            "Epoch 72, loss: 0.0824, val_loss: 0.1424, acc: 0.938\n",
            "Epoch 73, loss: 0.1110, val_loss: 0.2300, acc: 0.938\n",
            "Epoch 74, loss: 0.0791, val_loss: 0.1061, acc: 0.938\n",
            "Epoch 75, loss: 0.1002, val_loss: 0.1768, acc: 0.938\n",
            "Epoch 76, loss: 0.0719, val_loss: 0.0579, acc: 0.938\n",
            "Epoch 77, loss: 0.0810, val_loss: 0.0948, acc: 0.938\n",
            "Epoch 78, loss: 0.0610, val_loss: 0.0222, acc: 1.000\n",
            "Epoch 79, loss: 0.0601, val_loss: 0.0222, acc: 1.000\n",
            "Epoch 80, loss: 0.0514, val_loss: 0.0117, acc: 1.000\n",
            "Epoch 81, loss: 0.0498, val_loss: 0.0060, acc: 1.000\n",
            "Epoch 82, loss: 0.0454, val_loss: 0.0173, acc: 1.000\n",
            "Epoch 83, loss: 0.0472, val_loss: 0.0077, acc: 1.000\n",
            "Epoch 84, loss: 0.0430, val_loss: 0.0289, acc: 1.000\n",
            "Epoch 85, loss: 0.0449, val_loss: 0.0094, acc: 1.000\n",
            "Epoch 86, loss: 0.0400, val_loss: 0.0493, acc: 0.938\n",
            "Epoch 87, loss: 0.0430, val_loss: 0.0089, acc: 1.000\n",
            "Epoch 88, loss: 0.0374, val_loss: 0.0669, acc: 0.938\n",
            "Epoch 89, loss: 0.0429, val_loss: 0.0068, acc: 1.000\n",
            "Epoch 90, loss: 0.0361, val_loss: 0.0710, acc: 0.938\n",
            "Epoch 91, loss: 0.0422, val_loss: 0.0058, acc: 1.000\n",
            "Epoch 92, loss: 0.0349, val_loss: 0.0693, acc: 0.938\n",
            "Epoch 93, loss: 0.0411, val_loss: 0.0055, acc: 1.000\n",
            "Epoch 94, loss: 0.0337, val_loss: 0.0678, acc: 0.938\n",
            "Epoch 95, loss: 0.0397, val_loss: 0.0059, acc: 1.000\n",
            "Epoch 96, loss: 0.0326, val_loss: 0.0613, acc: 0.938\n",
            "Epoch 97, loss: 0.0376, val_loss: 0.0081, acc: 1.000\n",
            "Epoch 98, loss: 0.0316, val_loss: 0.0499, acc: 0.938\n",
            "Epoch 99, loss: 0.0349, val_loss: 0.0138, acc: 1.000\n",
            "Test acc: 0.900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpcxZ5Hr3eM-"
      },
      "source": [
        "## [Problem 3] Create a model of Iris using all three types of objective variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8y_ZYnM3KVb"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "X, y = df.loc[:, ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']], df['Species']\n",
        "X = np.array(X)\n",
        "y = np.array(y).reshape(-1, 1)\n",
        "y = OneHotEncoder(sparse=False).fit_transform(y)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZz2gx-48TNZ",
        "outputId": "7fdf3226-8ff0-4149-daf3-d2259a43473c"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((120, 4), (30, 4), (120, 3), (30, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaE00MyU-vBW",
        "outputId": "5e21fbeb-4109-4fec-c8e4-8c21cc2a262c"
      },
      "source": [
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "n_input = X_train.shape[1]\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_classes = y_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "\n",
        "# Placeholder\n",
        "X = tf.placeholder(tf.float32, [None, n_input])\n",
        "Y = tf.placeholder(tf.float32, [None, n_classes])\n",
        "\n",
        "# Mini batch\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# Network layers\n",
        "logits = example_net(X)\n",
        "\n",
        "# Objective function\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "\n",
        "# Optimization method\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Prediction\n",
        "correct_pred = tf.equal(tf.argmax(Y), tf.argmax(tf.nn.softmax(logits, axis=1)))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Init variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_batch = np.ceil(n_samples / batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "\n",
        "        for i, (mini_X, mini_y) in enumerate(get_mini_batch_train):\n",
        "            sess.run(train_op, feed_dict={X: mini_X, Y: mini_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_X, Y: mini_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        \n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: mini_X, Y: mini_y})\n",
        "        print(f\"Epoch {epoch}, loss: {total_loss:.4f}, acc: {total_acc:.3f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.3f}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Epoch 0, loss: 4.7694, acc: 0.033, val_loss: 0.0016, val_acc: 0.333\n",
            "Epoch 1, loss: 0.3614, acc: 0.056, val_loss: 1.5877, val_acc: 0.667\n",
            "Epoch 2, loss: 0.2166, acc: 0.081, val_loss: 0.0226, val_acc: 0.667\n",
            "Epoch 3, loss: 0.1867, acc: 0.089, val_loss: 0.0000, val_acc: 1.000\n",
            "Epoch 4, loss: 0.1340, acc: 0.086, val_loss: 0.0009, val_acc: 1.000\n",
            "Epoch 5, loss: 0.0450, acc: 0.094, val_loss: 0.0000, val_acc: 1.000\n",
            "Epoch 6, loss: 0.0517, acc: 0.086, val_loss: 0.0000, val_acc: 0.667\n",
            "Epoch 7, loss: 0.1532, acc: 0.083, val_loss: 0.0000, val_acc: 1.000\n",
            "Epoch 8, loss: 0.1074, acc: 0.081, val_loss: 0.0000, val_acc: 0.667\n",
            "Epoch 9, loss: 0.1797, acc: 0.089, val_loss: 0.0000, val_acc: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqOhRmSXDVoN"
      },
      "source": [
        "## [Problem 4] Creating a model of House Prices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "G-dDCkylDCX_",
        "outputId": "522fd066-3e95-4199-86a4-feba763a849b"
      },
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>...</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
              "0   1          60       RL  ...        WD         Normal    208500\n",
              "1   2          20       RL  ...        WD         Normal    181500\n",
              "2   3          60       RL  ...        WD         Normal    223500\n",
              "3   4          70       RL  ...        WD        Abnorml    140000\n",
              "4   5          60       RL  ...        WD         Normal    250000\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtDDDcstD3vN",
        "outputId": "df0ff1ea-105a-46f5-8714-6b5de209d729"
      },
      "source": [
        "X, y = df[[\"GrLivArea\", \"YearBuilt\"]], df[\"SalePrice\"]\n",
        "X = np.array(np.log1p(X))\n",
        "y = np.array(np.log1p(y))[:, np.newaxis]\n",
        "X, y"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[7.44483327, 7.60290046],\n",
              "        [7.14124512, 7.58933582],\n",
              "        [7.48829352, 7.60190196],\n",
              "        ...,\n",
              "        [7.75833347, 7.57147365],\n",
              "        [6.98378997, 7.57609734],\n",
              "        [7.13648321, 7.5837563 ]]), array([[12.24769912],\n",
              "        [12.10901644],\n",
              "        [12.31717117],\n",
              "        ...,\n",
              "        [12.49313327],\n",
              "        [11.86446927],\n",
              "        [11.90159023]]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACMhi6IjF25U",
        "outputId": "8cc1b7d1-d2bd-4fbb-e486-3a4c21f58936"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1168, 2), (292, 2), (1168, 1), (292, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyBdC3MOGLx8"
      },
      "source": [
        "def create_neural_network(X, y, layers=[]):\n",
        "    n_input = X.shape[1]\n",
        "    n_output = y.shape[1]\n",
        "\n",
        "    variable_shapes = [n_input] + [layer[\"n_nodes\"] for layer in layers] + [n_output]\n",
        "    W, B = [], []\n",
        "    for n0, n1 in zip(variable_shapes[:-1], variable_shapes[1:]):\n",
        "        W.append(tf.Variable(tf.random_normal([n0, n1])))\n",
        "        B.append(tf.Variable(tf.random_normal([n1])))\n",
        "    \n",
        "    Z = X\n",
        "    for i, layer in enumerate(layers):\n",
        "        l = layer[\"activation\"](tf.matmul(Z, W[i]) + B[i])\n",
        "        Z = l\n",
        "    return tf.matmul(Z, W[-1]) + B[-1]\n",
        "\n",
        "def train_regression(X_train, y_train, X_val, y_val,\n",
        "                     layers=[], optimizer=tf.train.AdamOptimizer(0.01),\n",
        "                     batch_size=1, epochs=10):\n",
        "    _X = tf.placeholder(tf.float32, [None, X_train.shape[1]])\n",
        "    _Y = tf.placeholder(tf.float32, [None, y_train.shape[1]])\n",
        "\n",
        "    get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "    # Network\n",
        "    net = create_neural_network(_X, _Y, layers)\n",
        "    loss_op = tf.reduce_mean(tf.square(net - _Y))\n",
        "    train_op = optimizer.minimize(loss_op)\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_batch = np.ceil(X_train.shape[0] / batch_size).astype(np.int)\n",
        "            total_loss = 0\n",
        "\n",
        "            for i, (mini_X, mini_y) in enumerate(get_mini_batch_train):\n",
        "                sess.run(train_op, feed_dict={_X: mini_X, _Y: mini_y})\n",
        "                total_loss += sess.run(loss_op, feed_dict={_X: mini_X, _Y: mini_y})\n",
        "            \n",
        "            total_loss /= X_train.shape[0]\n",
        "            val_loss = sess.run(loss_op, feed_dict={_X: X_val, _Y: y_val})\n",
        "            print(f\"Epoch {epoch}, loss: {total_loss:.4f}, val_loss: {val_loss:.4f}\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adsf6QHREGqm",
        "outputId": "eb3f8a4c-3ca2-497f-d96f-165186a17175"
      },
      "source": [
        "layer_1 = {\n",
        "    \"n_nodes\": 50,\n",
        "    \"activation\": tf.nn.relu\n",
        "}\n",
        "layer_2 = {\n",
        "    \"n_nodes\": 100,\n",
        "    \"activation\": tf.nn.relu\n",
        "}\n",
        "\n",
        "train_regression(X_train, y_train, X_val, y_val, layers=[layer_1, layer_2], batch_size=10, epochs=10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss: 311.8773, val_loss: 15.1369\n",
            "Epoch 1, loss: 0.9590, val_loss: 6.0154\n",
            "Epoch 2, loss: 0.3866, val_loss: 3.6285\n",
            "Epoch 3, loss: 0.1329, val_loss: 1.7315\n",
            "Epoch 4, loss: 0.0443, val_loss: 0.3415\n",
            "Epoch 5, loss: 0.0239, val_loss: 0.1625\n",
            "Epoch 6, loss: 0.0199, val_loss: 0.1505\n",
            "Epoch 7, loss: 0.0189, val_loss: 0.1383\n",
            "Epoch 8, loss: 0.0185, val_loss: 0.1375\n",
            "Epoch 9, loss: 0.0183, val_loss: 0.1178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xaBrdYhoFqW"
      },
      "source": [
        "## [Problem 5] Creating a MNIST model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gECAgYWeUj8v",
        "outputId": "a994f53b-b4f6-490c-b802-5788d856982f"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X, y), (X_test, y_test) = mnist.load_data()\n",
        "X.shape, X_test.shape, X[0].dtype"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28), dtype('uint8'))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3xm6sX3qdTy",
        "outputId": "6a20ce03-1508-407f-c1f0-e7e0a8c7470d"
      },
      "source": [
        "X = X.reshape(-1, 28 * 28).astype(np.float)\n",
        "X_test = X_test.reshape(-1, 28 * 28).astype(np.float)\n",
        "X /= 255\n",
        "X_test /= 255\n",
        "X.shape, X_test.shape, X.min(), X.max()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784), 0.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfQ-BoZTrFGn",
        "outputId": "964f1092-9463-40ad-f25d-04e9d52960dc"
      },
      "source": [
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_oh = encoder.fit_transform(y[:, np.newaxis])\n",
        "y_test_oh = encoder.transform(y_test[:, np.newaxis])\n",
        "y.shape, y_oh.shape, y_test_oh.shape\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_oh, test_size=0.2)\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 784), (12000, 784), (48000, 10), (12000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laf5EYRLrt7r"
      },
      "source": [
        "def lenet(x):\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([5, 5, 1, 6])),\n",
        "        'w2': tf.Variable(tf.random_normal([5, 5, 6, 16])),\n",
        "        'w3': tf.Variable(tf.random_normal([7 * 7 * 16, 120])),\n",
        "        'w4': tf.Variable(tf.random_normal([120, 84])),\n",
        "        'w5': tf.Variable(tf.random_normal([84, n_classes]))\n",
        "    }\n",
        "\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([6])),\n",
        "        'b2': tf.Variable(tf.random_normal([16])),\n",
        "        'b3': tf.Variable(tf.random_normal([120])),\n",
        "        'b4': tf.Variable(tf.random_normal([84])),\n",
        "        'b5': tf.Variable(tf.random_normal([n_classes])),\n",
        "    }\n",
        "\n",
        "    x = tf.reshape(x, [-1, 28, 28, 1])\n",
        "    conv_1 = tf.nn.conv2d(x, weights['w1'], strides=[1, 1, 1, 1], padding='SAME') + biases['b1']\n",
        "    conv_1 = tf.nn.relu(conv_1)\n",
        "    pool_1 = tf.nn.pool(conv_1, window_shape=[2, 2], strides=[2, 2],\n",
        "                        pooling_type='MAX', padding='VALID')\n",
        "    conv_2 = tf.nn.conv2d(pool_1, weights['w2'], strides=[1, 1, 1, 1], padding='SAME') + biases['b2']\n",
        "    conv_2 = tf.nn.relu(conv_2)\n",
        "    pool_2 = tf.nn.pool(conv_2, window_shape=[2, 2], strides=[2, 2],\n",
        "                        pooling_type='MAX', padding='VALID')\n",
        "    \n",
        "    x_reshape = tf.reshape(pool_2, [-1, 7 * 7 * 16])\n",
        "    layer_1 = tf.add(tf.matmul(x_reshape, weights['w3']), biases['b3'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w4']), biases['b4'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    \n",
        "    return tf.add(tf.matmul(layer_2, weights['w5']), biases['b5'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oWYHUiyvB2b",
        "outputId": "b994929f-e889-41a4-e053-0ec36f098634"
      },
      "source": [
        "lr = 0.01\n",
        "batch_size = 200\n",
        "epochs = 30\n",
        "\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = y_train.shape[1]\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, n_input])\n",
        "Y = tf.placeholder(tf.float32, [None, n_classes])\n",
        "\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "cnn = lenet(X)\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=cnn))\n",
        "optimizer = tf.train.AdamOptimizer(lr)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(Y, axis=1), tf.argmax(tf.nn.softmax(cnn), axis=1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss, total_acc = 0, 0\n",
        "\n",
        "        for i, (mini_X, mini_y) in enumerate(get_mini_batch_train):\n",
        "            sess.run(train_op, feed_dict={X: mini_X, Y: mini_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_X, Y: mini_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        \n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_train, Y: y_train})\n",
        "        print(f\"Epoch {epoch}, loss: {total_loss:.4f}, acc: {total_acc:.3f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.3f}\")\n",
        "    \n",
        "    test_loss, test_acc = sess.run([loss_op, accuracy], feed_dict={X: X_test, Y: y_test_oh})\n",
        "    print(f\"Test loss: {test_loss:.4f}, Test acc: {test_acc:.3f}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss: 4.6025, acc: 0.004, val_loss: 154.9071, val_acc: 0.897\n",
            "Epoch 1, loss: 0.5076, acc: 0.005, val_loss: 69.3372, val_acc: 0.930\n",
            "Epoch 2, loss: 0.2492, acc: 0.005, val_loss: 37.2842, val_acc: 0.949\n",
            "Epoch 3, loss: 0.1522, acc: 0.005, val_loss: 26.0699, val_acc: 0.956\n",
            "Epoch 4, loss: 0.0994, acc: 0.005, val_loss: 21.3223, val_acc: 0.959\n",
            "Epoch 5, loss: 0.0666, acc: 0.005, val_loss: 12.5711, val_acc: 0.971\n",
            "Epoch 6, loss: 0.0475, acc: 0.005, val_loss: 10.7327, val_acc: 0.972\n",
            "Epoch 7, loss: 0.0350, acc: 0.005, val_loss: 10.2882, val_acc: 0.971\n",
            "Epoch 8, loss: 0.0259, acc: 0.005, val_loss: 7.8881, val_acc: 0.977\n",
            "Epoch 9, loss: 0.0203, acc: 0.005, val_loss: 6.2422, val_acc: 0.980\n",
            "Epoch 10, loss: 0.0149, acc: 0.005, val_loss: 6.6677, val_acc: 0.979\n",
            "Epoch 11, loss: 0.0113, acc: 0.005, val_loss: 5.0326, val_acc: 0.983\n",
            "Epoch 12, loss: 0.0114, acc: 0.005, val_loss: 3.6447, val_acc: 0.987\n",
            "Epoch 13, loss: 0.0089, acc: 0.005, val_loss: 4.6765, val_acc: 0.984\n",
            "Epoch 14, loss: 0.0083, acc: 0.005, val_loss: 4.1528, val_acc: 0.984\n",
            "Epoch 15, loss: 0.0072, acc: 0.005, val_loss: 6.5489, val_acc: 0.979\n",
            "Epoch 16, loss: 0.0060, acc: 0.005, val_loss: 3.2405, val_acc: 0.988\n",
            "Epoch 17, loss: 0.0073, acc: 0.005, val_loss: 4.4591, val_acc: 0.984\n",
            "Epoch 18, loss: 0.0060, acc: 0.005, val_loss: 2.9705, val_acc: 0.989\n",
            "Epoch 19, loss: 0.0068, acc: 0.005, val_loss: 2.6122, val_acc: 0.990\n",
            "Epoch 20, loss: 0.0059, acc: 0.005, val_loss: 3.9664, val_acc: 0.986\n",
            "Epoch 21, loss: 0.0056, acc: 0.005, val_loss: 3.2645, val_acc: 0.988\n",
            "Epoch 22, loss: 0.0052, acc: 0.005, val_loss: 3.1874, val_acc: 0.989\n",
            "Epoch 23, loss: 0.0068, acc: 0.005, val_loss: 3.0950, val_acc: 0.990\n",
            "Epoch 24, loss: 0.0053, acc: 0.005, val_loss: 3.9491, val_acc: 0.988\n",
            "Epoch 25, loss: 0.0059, acc: 0.005, val_loss: 1.8235, val_acc: 0.993\n",
            "Epoch 26, loss: 0.0047, acc: 0.005, val_loss: 2.3279, val_acc: 0.992\n",
            "Epoch 27, loss: 0.0047, acc: 0.005, val_loss: 1.4930, val_acc: 0.993\n",
            "Epoch 28, loss: 0.0038, acc: 0.005, val_loss: 1.6938, val_acc: 0.993\n",
            "Epoch 29, loss: 0.0029, acc: 0.005, val_loss: 1.3424, val_acc: 0.993\n",
            "Test loss: 12.1003, Test acc: 0.975\n"
          ]
        }
      ]
    }
  ]
}