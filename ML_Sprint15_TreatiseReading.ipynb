{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Sprint15_TreatiseReading.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN7vT/K0qxYiiLiLAkjwWkO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanhnguyen2612/diveintocode-ml/blob/master/ML_Sprint15_TreatiseReading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVTnxfIJPnio"
      },
      "source": [
        "# Treatise Reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYMH-QroQFov"
      },
      "source": [
        "## 1. What kind of method exists in the field of object detection?\n",
        "*   Object proposals (Selective Search, CPMC, MCG, etc.)\n",
        "*   Deep networks (R-CNN, OverFeat, MultiBox, etc.)\n",
        "\n",
        "[Cite] 2. Related work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKDcnQAiQKS4"
      },
      "source": [
        "## 2. It says \"Faster\", but what mechanism was used to make it faster?\n",
        "*   Using 'attention' mechanism: Region of Interest + shared convolutional layers -> reduce time for computing proposals.\n",
        "*   Reduce model size with translation-Invariant multi-scale anchors.\n",
        "\n",
        "[Cite] 3. Faster R-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV1Y1sM6QOmX"
      },
      "source": [
        "## 3. How is the One-Stage method different from the Two-Stage method?\n",
        "*   One-stage detection (class-specific detection pipeline): the region-wise features come from a sliding window of one aspect ratio over a scale pyramid, simultaneously determine the location and category.\n",
        "*   Two-stage detection (Proposal + Detection): The region proposals task at first stage is same as one-stage method, detection phase uses attention technique to refine them -> more faithfully cover the features of the regions.\n",
        "\n",
        "[Cite] 4. Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "worOmp9aQRMP"
      },
      "source": [
        "## 4. What is RPN?\n",
        "Region Proposal Network: a small network slides over the convolutional feature map by the last shared convolutional layer -> generate a set of rectangular object proposals (each with an objectness score).\n",
        "\n",
        "[Cite] 3. Faster R-CNN (Figure 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVMu9iZAQSza"
      },
      "source": [
        "## 5. What is RoI pooling?\n",
        "*   A max pooling layer converts the feature inside any valid region of interest into a small feature map with a fix spatial extent of H x W.\n",
        "\n",
        "[Cite] 2. Related work + 4. Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-HJ7Og7QUp1"
      },
      "source": [
        "## 6. What is the proper size for Anchor?\n",
        "By default they use 3 scales & 3 ratios. It was experimented that using anchors of multiple sizes can be more effective.\n",
        "\n",
        "| settings | anchor scales | aspect ratio | mAP (%) |\n",
        "| --- | --- | --- | --- |\n",
        "| 1 scale, 1 ratio | 128^2 | 1:1 | 65.8 |\n",
        "| 1 scale, 1 ratio | 256^2 | 1:1 | 66.7 |\n",
        "| 1 scale, 3 ratios | 128^2 | {2:1, 1:1, 1:2} | 68.8 |\n",
        "| 1 scale, 3 ratios | 256^2 | {2:1, 1:1, 1:2} | 67.9 |\n",
        "| 3 scales, 1 ratio | {128^2, 256^2, 512^2} | 1:1 | **69.8** |\n",
        "| 3 scales, 3 ratios | {128^2, 256^2, 512^2} | {2:1, 1:1, 1:2} | **69.9** |\n",
        "\n",
        "[Cite] 4. Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0r1wkG0QI8u"
      },
      "source": [
        "## 7. What kind of data set is used and what kind of index value is obtained compared to the previous research?\n",
        "Datasets:\n",
        "*   PASCAL VOC 2007, 2012\n",
        "*   MS COCO\n",
        "Index value to measure is mean Average Precision (mAP), because this is the actual metric for object detection (rather than focusing on object proposal proxy metrics)\n",
        "\n",
        "[Cite] 4. Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l349RsgQW12"
      },
      "source": [
        "## 8. (Advance assignment) How is Faster R-CNN cited in the article on object detection newer than Faster R-CNN?"
      ]
    }
  ]
}